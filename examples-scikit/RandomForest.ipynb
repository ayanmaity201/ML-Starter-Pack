{
  "cells": [
    {
      "metadata": {
        "_uuid": "dcf93e819026cb68047eeec3137cc5c7288ec2a9",
        "_cell_guid": "086656c8-d230-4abc-a438-4ebf137a9e18"
      },
      "cell_type": "markdown",
      "source": "**Random Forest Classifier Example**"
    },
    {
      "metadata": {
        "_uuid": "5c9ad27a7c14ae19ac7d45177f744665fc7a71c3",
        "_cell_guid": "86d6b4ed-d7d2-4b23-becd-69e780fb08c4"
      },
      "cell_type": "markdown",
      "source": "In this notebook I am going to build a  Random Forest classifier to classify a data set of different classes of glass types . "
    },
    {
      "metadata": {
        "_uuid": "6dbc0e53980160c00b06426d1d42d63d1eaa4742",
        "_cell_guid": "4154b0bd-db9b-4ded-b577-c4c8b2516556",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a3a599286c8e4697fcbcf9c0c17d3e96bebd0fbb",
        "_cell_guid": "051e1916-4a96-4963-83ff-680be66933e4"
      },
      "cell_type": "markdown",
      "source": "Load the data in pandas Dataframe using pd.read_csv() method and take a quick look at the data and its attributes."
    },
    {
      "metadata": {
        "_uuid": "d54afacdddb4f2c669e0d18010a6e3780dd53321",
        "_cell_guid": "54ebc3a8-28d1-4b67-a226-da875a644bb1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv('../input/glass.csv')\ntrain_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "93fff55f1fe28e06191e71c913e907eacb813ddc",
        "_cell_guid": "8d55e78d-6724-4318-8158-7276cfbe7fe0"
      },
      "cell_type": "markdown",
      "source": "If data is not clean (i.e. some of the fields are NULL ) ,we have to clean the dada first. But using info() ,we see that data is pure,there is no null cell  in it."
    },
    {
      "metadata": {
        "_uuid": "f9e41905d8310c021cb1c66d55a0cbfd0bf352a6",
        "_cell_guid": "ee2bef2a-daa0-4925-a37d-311308b0a6aa",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a342115182b99f0b5b70cfa036109e3ed22b05cd",
        "_cell_guid": "f053f5a3-aa83-4551-80a5-5f8a6c528c74"
      },
      "cell_type": "markdown",
      "source": "Now look at that the unique classes in type attibute."
    },
    {
      "metadata": {
        "_uuid": "9faab4efed6cbdb7bac24e847b51e5c423082843",
        "_cell_guid": "92c502e9-4396-4ae1-acaa-4fe73c5d171d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df['Type'].unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "232fc01332875895ce4fb34aab0284620853b7e8",
        "_cell_guid": "ec178bf2-1784-411a-9b3a-6db00c9f1b6c"
      },
      "cell_type": "markdown",
      "source": "Take a look at the distribution of the different Type or classes in the data."
    },
    {
      "metadata": {
        "_uuid": "0ac55af31261bc31e1e76baa6f200a4009357dc4",
        "_cell_guid": "31697f18-abb1-4a79-99fb-e4ffb14c5073",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.Type.value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0115412fe366bd840a14c3da27be8d33289e46f3",
        "_cell_guid": "1ae35aae-b9cf-4678-9ecf-96be3623977d"
      },
      "cell_type": "markdown",
      "source": "Now we process the data to be used in the classifier. We form the numpy array of the data and take the class into target numpy array."
    },
    {
      "metadata": {
        "_uuid": "1fb14c8841ce8b7b07babd1c5dde1cfe14e685c9",
        "_cell_guid": "479a7757-52c4-40ba-a161-fd7fc7eed25e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "target = train_df['Type'].values\ndel train_df['Type']\ntrain_x = train_df.as_matrix()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0f3f7feb3a8658620b76194c62ef0d1520eb53e2",
        "_cell_guid": "3afa7957-b634-4ae0-8b38-f5f2f84ea3c7"
      },
      "cell_type": "markdown",
      "source": "Finally here we built the classifier for the RF model. First we have to import RandomForestClassifier form sklearn.ensemble. Then we bulit the classifier with some hyperparameters tuned manually. Basically RFClassifier has  lots of hyperparameters but we leave most of them to be set to default .We just manually set n_estimators ,which is nothing but the no of decision tree classifier models it will use and max_depth ,which is the maximum depth of every decision tree inthe RF model."
    },
    {
      "metadata": {
        "_uuid": "d47a039efbbda97d57d9bcbdd8694c48f2497a50",
        "_cell_guid": "b3c64916-24d5-41d9-bc00-258fbf5396d3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=20,max_depth=10)\nclf.fit(train_x,target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8566de03a881b743696f366e9919cc4918d2181e",
        "_cell_guid": "86f42888-e2ec-4f17-8878-15ae6c76257b"
      },
      "cell_type": "markdown",
      "source": "We find the accuracy using score method and we see that it gives a whooping 99% accuracy. So, this proves RF may be the best model to chose for this classification problem."
    },
    {
      "metadata": {
        "_uuid": "1d2174fb80dda1b9f75441e23d3c2b69d33ba46b",
        "_cell_guid": "48134efd-9e86-48af-b401-b9fb5410cfdc",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "clf.score(train_x,target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "668506d99eeb2a31857c78f844c47a9329f6731a",
        "_cell_guid": "fe2b92e1-f807-47c4-b5a2-b2b1724e8c3a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}